Dedicated Model CIFAR Performance:
[[606  37  52  13  21  17  16  19 164  55]
 [ 50 597  10  18   8  15  15  24  67 196]
 [114  26 322  45 145 131  78  68  45  26]
 [ 38  38  77 203  57 273 133  95  36  50]
 [ 63  17 134  41 367  82 120 127  30  19]
 [ 23  17 106 105  89 417  88 102  30  23]
 [ 23  21  70  56 125  66 523  73  13  30]
 [ 50  12  36  40  95  95  37 571  15  49]
 [184  68  20  18  13  19  13  17 563  85]
 [ 69 178  13  23  11  21  19  39  84 543]]
              precision    recall  f1-score   support

           0       0.50      0.61      0.55      1000
           1       0.59      0.60      0.59      1000
           2       0.38      0.32      0.35      1000
           3       0.36      0.20      0.26      1000
           4       0.39      0.37      0.38      1000
           5       0.37      0.42      0.39      1000
           6       0.50      0.52      0.51      1000
           7       0.50      0.57      0.53      1000
           8       0.54      0.56      0.55      1000
           9       0.50      0.54      0.52      1000

    accuracy                           0.47     10000
   macro avg       0.46      0.47      0.46     10000
weighted avg       0.46      0.47      0.46     10000



Multitask Model CIFAR Performance:
Loss: 1.1202881336212158
[[644  24  44  37   7   6  19  10 169  40]
 [ 28 703   8  14   3   8  20   9  73 134]
 [ 88   9 411 157  86  81  99  25  31  13]
 [ 29  13  63 540  39 129 105  28  35  19]
 [ 35   4 118 145 413  49 129  74  29   4]
 [ 15   7  52 335  37 450  26  43  24  11]
 [  7   6  34 115  39  14 758   5  17   5]
 [ 20   8  29 107  52  85  11 660  13  15]
 [ 62  47   9  23   5   5   9   5 796  39]
 [ 40 131   9  25   3   4  17  25  74 672]]
              precision    recall  f1-score   support

           0       0.67      0.64      0.65      1000
           1       0.74      0.70      0.72      1000
           2       0.53      0.41      0.46      1000
           3       0.36      0.54      0.43      1000
           4       0.60      0.41      0.49      1000
           5       0.54      0.45      0.49      1000
           6       0.64      0.76      0.69      1000
           7       0.75      0.66      0.70      1000
           8       0.63      0.80      0.70      1000
           9       0.71      0.67      0.69      1000

    accuracy                           0.60     10000
   macro avg       0.62      0.60      0.60     10000
weighted avg       0.62      0.60      0.60     10000



Multitask Model Digit Performance:
Loss: 0.060937896370887756
[[ 973    0    1    1    0    1    1    0    3    0]
 [   0 1123    2    3    0    0    3    0    4    0]
 [   2    3 1015    2    0    0    0    7    3    0]
 [   1    1    3  994    0    7    0    1    3    0]
 [   2    0    7    0  951    0    2    1    1   18]
 [   2    0    1    7    0  877    4    0    1    0]
 [   8    1    1    0    1    8  935    0    4    0]
 [   1    1    3    4    0    0    0 1010    2    7]
 [   7    1    2    4    1    5    0    3  950    1]
 [   7    6    2    2    2    3    0    2    3  982]]
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.98      0.98      1032
           3       0.98      0.98      0.98      1010
           4       1.00      0.97      0.98       982
           5       0.97      0.98      0.98       892
           6       0.99      0.98      0.98       958
           7       0.99      0.98      0.98      1028
           8       0.98      0.98      0.98       974
           9       0.97      0.97      0.97      1009

    accuracy                           0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

Multitask Model Fashion Performance:
Loss: 0.3078683316707611
[[853   0  19  27   2   2  87   0  10   0]
 [  2 963   1  25   4   0   3   0   2   0]
 [ 16   0 872   7  58   1  46   0   0   0]
 [ 21   4  19 909  16   1  25   0   5   0]
 [  1   0  84  46 819   0  50   0   0   0]
 [  0   0   0   0   0 983   0  12   1   4]
 [137   0  92  24  79   0 660   0   8   0]
 [  0   0   0   0   0  20   0 941   1  38]
 [  4   1   7   5   1   4   5   3 970   0]
 [  0   0   0   0   0   8   1  26   0 965]]
              precision    recall  f1-score   support

           0       0.82      0.85      0.84      1000
           1       0.99      0.96      0.98      1000
           2       0.80      0.87      0.83      1000
           3       0.87      0.91      0.89      1000
           4       0.84      0.82      0.83      1000
           5       0.96      0.98      0.97      1000
           6       0.75      0.66      0.70      1000
           7       0.96      0.94      0.95      1000
           8       0.97      0.97      0.97      1000
           9       0.96      0.96      0.96      1000

    accuracy                           0.89     10000
   macro avg       0.89      0.89      0.89     10000
weighted avg       0.89      0.89      0.89     10000

