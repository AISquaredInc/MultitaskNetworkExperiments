Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz
    16384/170498071 [..............................] - ETA: 0s   434176/170498071 [..............................] - ETA: 22s  4096000/170498071 [..............................] - ETA: 4s   9887744/170498071 [>.............................] - ETA: 2s 15654912/170498071 [=>............................] - ETA: 2s 21422080/170498071 [==>...........................] - ETA: 1s 27205632/170498071 [===>..........................] - ETA: 1s 32923648/170498071 [====>.........................] - ETA: 1s 38739968/170498071 [=====>........................] - ETA: 1s 44539904/170498071 [======>.......................] - ETA: 1s 50307072/170498071 [=======>......................] - ETA: 1s 56008704/170498071 [========>.....................] - ETA: 1s 61808640/170498071 [=========>....................] - ETA: 1s 67502080/170498071 [==========>...................] - ETA: 1s 73310208/170498071 [===========>..................] - ETA: 0s 79110144/170498071 [============>.................] - ETA: 0s 84787200/170498071 [=============>................] - ETA: 0s 90611712/170498071 [==============>...............] - ETA: 0s 96280576/170498071 [===============>..............] - ETA: 0s101965824/170498071 [================>.............] - ETA: 0s107798528/170498071 [=================>............] - ETA: 0s113532928/170498071 [==================>...........] - ETA: 0s119234560/170498071 [===================>..........] - ETA: 0s125050880/170498071 [=====================>........] - ETA: 0s130768896/170498071 [======================>.......] - ETA: 0s136519680/170498071 [=======================>......] - ETA: 0s142368768/170498071 [========================>.....] - ETA: 0s148119552/170498071 [=========================>....] - ETA: 0s153919488/170498071 [==========================>...] - ETA: 0s159612928/170498071 [===========================>..] - ETA: 0s165371904/170498071 [============================>.] - ETA: 0s170500096/170498071 [==============================] - 2s 0us/step
170508288/170498071 [==============================] - 2s 0us/step
Dedicated Model CIFAR Performance:
[[588  29  63  17  63  10  18  23 141  48]
 [ 39 677   6  20   6   7  17  11  39 178]
 [ 72  18 394  62 228  59  82  40  30  15]
 [ 28  43 102 291 150 135 138  56  13  44]
 [ 31  11  83  51 584  27  91  89  22  11]
 [ 15  18 140 173 173 280  84  83  16  18]
 [ 13  26  56  60 150  38 558  40   9  50]
 [ 21  15  60  44 135  49  40 592  14  30]
 [123  92  30  18  27   8   6   9 631  56]
 [ 53 174  12  14  13  16  21  41  54 602]]
              precision    recall  f1-score   support

           0       0.60      0.59      0.59      1000
           1       0.61      0.68      0.64      1000
           2       0.42      0.39      0.40      1000
           3       0.39      0.29      0.33      1000
           4       0.38      0.58      0.46      1000
           5       0.45      0.28      0.34      1000
           6       0.53      0.56      0.54      1000
           7       0.60      0.59      0.60      1000
           8       0.65      0.63      0.64      1000
           9       0.57      0.60      0.59      1000

    accuracy                           0.52     10000
   macro avg       0.52      0.52      0.51     10000
weighted avg       0.52      0.52      0.51     10000



Multitask Model CIFAR Performance:
[[697  21  39  17  25   6   5  20 131  39]
 [ 49 706   8  14   7   3   9  10  72 122]
 [110  11 428  65 150  60  41  83  36  16]
 [ 32  22  84 340 111 162  69  92  45  43]
 [ 45   6  88  54 563  30  38 140  26  10]
 [ 19   4 101 149  98 430  11 131  35  22]
 [ 16  16  63  84 135  32 588  27  20  19]
 [ 20   4  34  38  73  53   7 726  17  28]
 [ 92  44  11  11   6   3   3  12 796  22]
 [ 61 127  14  16  11  11  11  34  69 646]]
              precision    recall  f1-score   support

           0       0.61      0.70      0.65      1000
           1       0.73      0.71      0.72      1000
           2       0.49      0.43      0.46      1000
           3       0.43      0.34      0.38      1000
           4       0.48      0.56      0.52      1000
           5       0.54      0.43      0.48      1000
           6       0.75      0.59      0.66      1000
           7       0.57      0.73      0.64      1000
           8       0.64      0.80      0.71      1000
           9       0.67      0.65      0.66      1000

    accuracy                           0.59     10000
   macro avg       0.59      0.59      0.59     10000
weighted avg       0.59      0.59      0.59     10000



Multitask Model Digit Performance:
[[ 974    0    1    0    0    0    1    2    2    0]
 [   0 1126    2    0    0    1    2    1    3    0]
 [   1    1 1020    2    1    0    0    5    2    0]
 [   0    0    4  995    0    4    0    1    6    0]
 [   2    0    3    0  974    0    1    0    1    1]
 [   2    0    0    9    0  874    6    0    1    0]
 [   4    1    1    0    5    1  944    0    2    0]
 [   1    2    8    2    0    0    0 1010    2    3]
 [   2    0    4    3    1    2    0    3  957    2]
 [   3    2    0    4   10    4    0    1    5  980]]
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.99      0.98      1032
           3       0.98      0.99      0.98      1010
           4       0.98      0.99      0.99       982
           5       0.99      0.98      0.98       892
           6       0.99      0.99      0.99       958
           7       0.99      0.98      0.98      1028
           8       0.98      0.98      0.98       974
           9       0.99      0.97      0.98      1009

    accuracy                           0.99     10000
   macro avg       0.99      0.99      0.99     10000
weighted avg       0.99      0.99      0.99     10000

Multitask Model Fashion Performance:
[[832   1  13  14   7   2 125   0   5   1]
 [  2 979   0  10   4   0   5   0   0   0]
 [ 13   0 838   9  61   0  78   0   1   0]
 [ 17   7  14 920  14   0  26   0   2   0]
 [  3   0  67  36 842   0  52   0   0   0]
 [  0   0   0   0   0 968   0  13   0  19]
 [ 87   0  62  28  62   0 752   0   9   0]
 [  0   0   0   0   0  10   0 963   0  27]
 [  4   0   2   4   3   3   4   2 978   0]
 [  0   0   0   0   0   3   1  28   0 968]]
              precision    recall  f1-score   support

           0       0.87      0.83      0.85      1000
           1       0.99      0.98      0.99      1000
           2       0.84      0.84      0.84      1000
           3       0.90      0.92      0.91      1000
           4       0.85      0.84      0.84      1000
           5       0.98      0.97      0.97      1000
           6       0.72      0.75      0.74      1000
           7       0.96      0.96      0.96      1000
           8       0.98      0.98      0.98      1000
           9       0.95      0.97      0.96      1000

    accuracy                           0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000

